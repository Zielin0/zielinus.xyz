---
title: "AI and LLMs"
description: "How AI makes people retarded (including me)"
slug: "ai-and-llm"
tags:
    - "philosophy"
    - "psychology"
    - "ai"
updated: "2025-06-28"
---

In this article I will explore the Vocabulary Misuse of certain AI terms and words.

I will also explore the idea of Mental Degradation in our brains caused by the usage of AI.

~

By saying we, our, and generally using plural pronouns, I mean us as a modern society, anyone

that has access to the internet, a smartphone, or a computer.

# Vocabulary Misuse

AI is quite new. Or is it? Maybe LLMs are new? Or are they?

Anyone who knows the definition of these two, will notice that a lot of people use these words

incorrectly. Let's explore this idea.

## AI vs LLM

Like I said in the little intro, people use these incorrectly. Most of the time.

What actually the majority of people do, is to confuse them with each other, or use them

interchangably. Which is incorrect. But does that even matter?

## The Meaning AI

AI is an abbreviation of [Artificial Intelligence](https://en.wikipedia.org/wiki/Artificial_intelligence).

Artificial Intelligence is a very, very broad term. The Wikipedia article is long,

so let me shorten it.

> Artificial intelligence (AI) is the capability of computational systems to perform tasks

> typically associated with human intelligence, such as learning, reasoning,

> problem-solving, perception, and decision-making.

So, Artificial Intelligence, based on the name, is meant to simulate some sort of intelligence.

Since people created AI, we can say that AI tries to simulate the human intelligence. Most of

the time at least. The Wikipedia definition also says that AI is used of problem-solving,

perception, and decision-making. This is the most basic description of AI. But a good one.

It's just true. But let's talk about some examples of Artificial Intelligence.

### Deep Learning, predictions, and decisions

Artificiall Intelligence could be used to make predictions, and then make decisions based

on these predictions, which are generated using data from deep learning, or just learning.

Though predictions could be made without making decisions afterwards.

So how does it work? A program is given some data, this data is usually called a dataset,

it contains training data for the AI. The program then saves its model, and upon giving

related data, but not the same as in the training dataset, the model should be able to predict

what the data is, and perhaps make a decision based on that data and/or predictions.

### NLP, perception, and social intelligence

NLP, or Natural Language Processing, is used for communication with the human language.

Machine perception is the usage of various sensors such as cameras or microphones to

analyze some senses, and other stuff.

Social Intelligence is used to simulate human feelings, emotions and moods, that would be

presented by some sort of machine.

All of this is used to simulate a human. NLP for communication, Machine Perception for senses,

and Social Intelligence for feelings and emotions.

### Artificial General Intelligence

A type of AI which would posses the intelligence equal or greater than humans.

## The Meaning of LLM

LLM, or Large Language Model, is a type of Artificiall Intelligence, which is able to

communicate with a human, using a human language. LLMs are trained with large amounts of

texts, and use NLP (Natural Language Processing).

> The largest and most capable LLMs are generative pretrained transformers (GPTs), [...]

LLMs can be fine-tuned for specific uses.

## The History

One thing that people seem to misunderstand sometimes (it's less frequent now, but still

relevant) is that AI is completely new. That is incorrect. AI has existed for a while now.

It has basically existed as long as computers exist. LLMs are quite recent, but still not

as recent as these GPT chat-like AIs.

## Is that an issue?

Does it even matter if people confuse these two, or use them interchangably?

Probably not. Nobody really cares about it. They hear something trendy and just say it without

any research or thinking.

Where it's the biggest issue is companies using these words for their products.

Which is stupid, and I will cover that in the second part of this article.

But I guess people don't care what they say. Obviously there are people who try to use

these words properly. But maybe it's better to isolate oneself from this AI world and not

listen to any of these people talking about it.

# Mental Degradation

This is the main course of this article. What is in the description of this article.

How AI makes people stupid and retarded, including me (unfortunately),

but it seems like there is no escape from it in the modern world. It seems like there

is an oversaturation of AI-themed everything. Like why the f\*ck is some ChatGPT wannabe

AI agent in my chat app, any chat app for that matter, facebook messenger, whatsapp, instagram,

snapchat. Most of these are pure sh\*t of a software that shouldn't exist. Some are decent.

But still, why is it everywhere?

## Overuse and Misuse

There is this hype about LLMs and AI which is just disgusting at this point...

People use AI for literally everything. Or at least most do, I envy people who are disciplined

enough to not use tools like ChatGPT or others. Though, using other tools like Google, or

other search engines might be impossible with the ammount of AI slop generated and

search-engine-optimized.

### School

This is probably the most common use of AI honestly. For doing boring stuff, mostly for school.

Like writing essays, doing homework, and stuff like that. It's fine if it's done once or twice

a semester. But it's not fine when it's done every single time. And there are people who

are just so brain-rotten that don't even care about anything, tell LLMs like ChatGPT to do

their homework, don't even check for mistakes, bother to change some stuff up, and just submit

thing with a bunch of errors. If you're smart then you know why it's a problem. If you're not

smart then let me explain:

As we know school is supposed to teach. Students are supposed to learn things. If students

rely on LLMs and other AIs for doing their homework, they won't learn anything. And this is

the problem. Not learning anything obviously makes people stupid.

### Work

People not only use LLMs for school-related things, they also use them for work related things.

Which also makes them stupid, because in work you learn by experience, and if you rely

on something like a large language model, you won't learn sh*t through experience.

#### Programming

<small>This is not only about professional programming for money but also programming in general.</small>

There are people who call themselves "programmers" but will use ChatGPT or GitHub Co*kpilot

for generating code. **Which most of the time doesn't even work**. And then they will

submit this non-working and untested ai-generated slop code as a contribution to a serious

open-source project or a real-world job project/product/service.

And then proper thinking programmers will have to clean that code up, or fix weird merge

conflicts if someone who isn't thinking accepted the merge/pull request.

It really causes more issues than it solves.

And just like with students not being able to learn, "programmers" like these mentioned above

will not be able to learn proper programming as well, as they will rely on LLMs and code

generators.

#### Other

People will also use AIs amd LLMs for other work, not related to programming.

Like accountants, teachers, and others. It does not only make them stupid, it also poses

a big risk for any clients/coworkers/students and other people.

Students already use LLMs to do their homework, but the sad thing is that teachers also

use these tools for generating tests, homeworks, and other assignments.

At this point AI is generating and solving its tests, which doesn't make any sense.

Also imagine accountants using these tools to generate spreadsheets about taxes and stuff

like that. I bet there are some like that. And this is very dangerous, both for them and their

clients. For obvious reasons. Tax fraud is not fun. Not fun at all.

## Trendiness

Unfortunately that's the truth. AI is very trendy. You hear about it everywhere. It's on

most websites, advertised in most products and services. It's also easy to access.

For ChatGPT you don't even have to register properly, you can connect your google account

and provide a phone number for verification. You can also use it without signing up, with

limited features of course. The same goes for most of other GPT tools and services.

So maybe because it's that easy to access and so trendy, people tend to use it more.

And perhaps even pay for these services to be able to prompt a better model, generate

images or videos, and things like that.

## Stupid companies

The hype is so huge that AI is everywhere. A phone with built-in AI. A laptop with built-in

AI. A fridge with built-in AI. Like what does that even mean? A GPT-like applicaton, that

you maybe have to pay for? Why does that even matter? If you really need a GPT you can

always download ChatGPT, Claude, Perplexity or other apps onto your phone, or a laptop.

But I guess you can't really download AI for a fridge.

I do not understand this hype but I heard a good reason somewhere from someone.

Perhaps it was from [Tsoding](https://twitch.tv/Tsoding) but I'm not sure.

The person said:

> AI- is the smart- of these times. Like in the past you had something like smart-fridge,

> smart-printer. Now you have an AI-fridge or an AI-printer.

Maybe it's that, maybe it's just because of money. I don't know. But nontheless it looks

very stupid.

## Art and Copyright

While copyright has degraded over the years into some weird money scheme, art of any sort

is still an intellectual property of the creator. The issue is that these companies

creating these AI tools don't care about any copyrights and any intellectual properties.

They will use anything they can find on the internet, no matter the license, patents, and other

lawful stuff like that. They will use that to train their models. Image generation is

advancing really fast but a lot of data for these models has been gathered illegaly I guess.

With no respect for the intellectual property and things like that. And it doesn't only

refer to visual art. It's also about the text. I'm sure some of the models have been trained

on pirated books and papers. While I can understand piracy in some cases, I cannot

understand it when the pirate is a multi-million dollar company which will make more

with the model they are training right now, on the pirated content.

## Me

I am a victim of this mind virus. And I think people I mentioned above all are victims

of this mind virus. It's not physical, it's psychological. Just like the addiction

to short-form content so prevalent at this time in history.

I have used ChatGPT and Perplexity for a lot of things. Including whatever I mentioned above.

School or programming. Yeah I did it. And I'm ashamed of that. I made myself retarded.

I was lazy, did not want to learn. So I used AI to help me with my homework or to program

something for me. It did not go well in both cases. But I was still vigilant about

whatever is generated by the AI. I tried the code, didn't work, next prompt, maybe this time

it'll work. Nope, next prompt, nope again, give up. That's how it went with programming.

As to school, it was mostly correct, I had to point out some mistakes, and then it was fully

correct. And I always changed some words up, made my own sentences based on these generated ones.

I never copied exactly whatever AI has generated, so I guess I wasn't as retarded as others are.

And to this time I still use ChatGPT or Perplexity for stuff, just not for things that will

make me retarded. And I do think there is a potential to learn from AI. Which I will talk about

below.

## Important Note

I just want to say, after all of these points I made, that there still are some

respectable people and companies which despise the use of AI/LLMs. And they have my

respect. I'm just describing the majority above.

# Good Uses

If used properly, AI can actually help, be useful, and not make people stupid at the same time.

## Search Engine

Since google and other search engines are completely trashed with ai-generated slop, GPT models

like ChatGPT actually became better search engines. And they are even better than classic

search engines because they accept human language instead of weirdly engineered search

prompts. So instead of writing a couple of words into the search bar, you can type a sentence,

or a question into the text box in tools like ChatGPT. And what's even better about it is that

it will actually respond in a human-readable way, it will point stuff out. Make lists, tables,

and all the good stuff. There are some drawbacks of that use though:

1. It can hallucinate stuff; if you ask about something obscure, or relatively new, AI can

hallucinate stuff out and just give you wrong answers.

2. It will not give you information about everything, or will purposefully omit some stuff

because of the developer prompts. Sometimes it doesn't want to talk about politics and other

stuff like that.

There are probably more which I cannot remember right now. But it's way better than typing

some words into a search bar and then clicking every link, checking if it's what you want, and

doing that until you find what you need to find.

## Learning

And I mean learning as in learning **with** AI and **about** AI.

### With

Since GPTs already use human language, and most of them have some sort of memory, you

can actually have a conversation with these models. And the data of the model is so huge,

that you can ask it about basically anything and it will do its best to try to explain it to you.

This actually works pretty well for learning.

If you want to learn about something then the first thing you do is ask a question.

When GPTs weren't a thing or weren't available for the general public, we'd just type that

question into google, youtube, or reddit. Then we'd have to read articles, or watch videos to

learn. And that is a good way to learn. Any way is a good way to learn. But it's easier with

GPTs and LLMs. You just ask a question, it will explain, if it's something that it can explain.

And if you have more questions, which you always should, you can ask them and get answers.

### About

I see huge nerd value in learning about AIs and LLMs. Exploring how it all works.

How the models are trained, how they recognize things, and stuff like that.

It's very interesting at the lower level, how these models are constructed out of

artificial neuron networks, how the data is processed in these neurons and all that.

It's very cool to think about and very cool to explore.

I would personally like to explore it one day, perhaps make something of my own.

# A Hope

I have some hopes about the state of AI. Might be naive, *but it's fun to fantasize*.

## For Me

For myself, I hope to use AI and LLMs as a form of making myself stupid. It is inevitable

that I will still use GPTs as a replacement for search engines. DuckDuckGo is not that bad,

which is the search engine i use the most. But google is just gone. Also I think

using it for learning is good. And I do that a lot. And I will still do that.

But I hope to use it less and less, however I still like to learn a lot and will probably

have to use it no matter what. I cannot eliminate the use of GPTs for myself, but I can

make it as low as possible. And I hope to never use it for programming or school.

## For Others

For others, I hope that people will wake up. I hope that people will notice that there's

something wrong with them. That they are getting stupid and retarded, because AI is doing

their homework. And I hope that all of these companies will stop doing whatever they

are doing right now. Perhaps there should be a set of laws created specifically for AIs.

Like using Artificial Intelligence in the place of work should be forbidden and punishable.

I think there should be a set of rules that companies which are traning new models should

follow.

# Conclusion

AI and LLMs make people retarded. Most of them at least. I was using AI in a way that I now

regret. But there is hope, there are respectable people and companies which despise the

common use of AI and LLMs. And finally, there are good uses of AI and LLMs, it's not like

every time you ask ChatGPT something you make yourself more stupid.

~

Well... This article was not that fun to write as the previous one. But I think I had

to get all of this out of myself. And I hope to never write about this again. Perhaps the topic

of AI is still immature to talk about, there still are people who don't know what they're doing.

Perhaps that is me as well. Perhaps I don't know what I'm doing or saying. Who knows?

If you read this article, then thanks I guess. If you noticed any mistakes then email me at

[me@zielinus.xyz](mailto:me@zielinus.xyz) or message me on discord [@zielino](https://discord.com).

:wq!

\- ziel

